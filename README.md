Today's music ecosystem is permeated by digital technology — from recording to production to distribution to consumption. Intelligent technologies and interfaces play a crucial role during all these steps. On the music creation side, tools and interfaces like new sensor-based musical instruments or software like digital audio workstations (DAWs) and sound and sample browsers support creativity. Generative systems can support novice and professional musicians by automatically synthesising new sounds or even new musical material. On the music consumption side, tools and interfaces such as recommender systems, automatic radio stations, or active listening applications allow users to navigate the virtually endless spaces of music repositories.

Both ends of the music market therefore heavily rely on and benefit from intelligent approaches that enable users to access sound and music in unprecedented manners. This ongoing trend draws from manifold areas such as interactive machine learning, music information retrieval (MIR) — in particular content-based retrieval systems, recommender systems, human computer interaction, and adaptive systems, to name but a few prominent examples. The Workshop on Intelligent Music Interfaces for Listening and Creation (MILC 2018) will bring together researchers from these communities and provide a forum for the latest trends in user-centric machine learning and interfaces for music consumption and creation.

## Important Dates
- December 17, 2017: Deadline for normal paper submission
- January 23, 2018: Acceptance notification for normal paper submissions
- February 6, 2018: Deadline for final copy of accepted papers
- March 11, 2018: Workshop date

## Organisers
- Peter Knees, Vienna University of Technology, Austria (peter.knees@tuwien.ac.at)
- Markus Schedl, Johannes Kepler University Linz, Austria (markus.schedl@jku.at)
- Rebecca Fiebrink, Goldsmiths, University of London, UK (r.fiebrink@gold.ac.uk)
