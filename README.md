## Workshop Schedule
#### 9:15-9:25	Welcome
#### 9:25-10:45 Session 1 - *Personalization*
- How Automated Recommendations Affect the Playlist Creation Behavior of Users (Iman Kamehkhosh, Dietmar Jannach, Geoffray Bonnin)
- geMsearch: Personalized Explorative Music Search (Christian Esswein, Markus Schedl, Eva Zangerle)
- MedleyAssistant - A system for personalized music medley creation (Zhengshan Shi, Gautham J. Mysore)

#### 10:45-11:00 *Coffee Break*
#### 11:00-12:30 Session 2 - *Interaction*
- An environment for machine pedagogy: Learning how to teach computers to read music (Gabriel Vigliensoni, Jorge Calvo-Zaragoza, Ichiro Fujinaga)
- Beyond a Skeuomorphic Representation of Subtractive Synthesis (Martin Lindh)
- Overviewing a field of self-organising music interfaces: autonomous, distributed, environmentally aware, feedback systems (Phivos-Angelos Kollias)

#### 12:30-13:30 *Lunch*
#### 13:30-15:00 Session 3 - *Composition*
- Learning Latent Representations of Music to Generate Interactive Musical Palettes (Adam Roberts, Jesse Engel, Sageev Oore, Douglas Eck)
- Lumanote: A Real-Time Interactive Music Composition Assistant (James Granger, Mateo Aviles, Joshua Kirby, Austin Griffin, Johnny Yoon, Raniero Lara-Garduno, Tracy Hammond)
- *Demos and Final Remarks*

#### 15:00-15:15 *Coffee Break*

## Motivation
Today's music ecosystem is permeated by digital technology — from recording to production to distribution to consumption. Intelligent technologies and interfaces play a crucial role during all these steps. On the **music creation** side, tools and interfaces like new sensor-based musical instruments or software like digital audio workstations (DAWs) and sound and sample browsers support creativity. Generative systems can support novice and professional musicians by automatically synthesising new sounds or even new musical material. On the **music consumption** side, tools and interfaces such as recommender systems, automatic radio stations, or active listening applications allow users to navigate the virtually endless spaces of music repositories.

Both ends of the music market therefore heavily rely on and benefit from intelligent approaches that enable users to access sound and music in unprecedented manners. This ongoing trend draws from manifold areas such as interactive machine learning, music information retrieval (MIR) — in particular content-based retrieval systems, recommender systems, human computer interaction, and adaptive systems, to name but a few prominent examples. The **Workshop on Intelligent Music Interfaces for Listening and Creation (MILC 2018)** will bring together researchers from these communities and provide a forum for the latest trends in user-centric machine learning and interfaces for music consumption and creation.

## Exemplary Topics of Interest
- Music and audio search interfaces
- Adaptive music user interfaces
- Music learning interfaces
- Music recommender systems
- Gamification in music interfaces
- Novel visualization paradigms
- New technologies for human expression, creativity, and embodied interaction
- Machine learning for new digital musical instruments
- Gestural interfaces for music creation and listening
- Accessible music making technologies
- Intelligent systems for music composition
- User modeling for personalized music interfaces

## Submissions
All papers must be original and not simultaneously submitted to another journal or conference. We solicit three types of submissions:
- **Full papers** (up to 6 pages)
- **Short papers** (up to 4 pages)
- **Demo papers** (up to 4 pages)

Submissions must follow the standard SigCHI format, using one of the following templates: [LaTeX](https://github.com/sigchi/Document-Formats/tree/master/LaTeX), [Microsoft Word](http://st.sigchi.org/sigchi-paper-template/SIGCHIPaperFormat.docx). Note that **references count towards the page limits**.

Please **anonymize your submission (double-blind reviewing policy)** and submit your paper via [EasyChair](https://easychair.org/conferences/?conf=iui2018milc). Submissions will be reviewed by at least three members of the program committee. Authors of accepted submissions will be required to attend and give a presentation at the workshop. 

## Important Dates
- ~~December 17, 2017: Deadline for paper submission~~
- ~~January 23, 2018: Acceptance notification for paper submissions~~
- ~~February 6, 2018: Deadline for final copy of accepted papers~~
- March 11, 2018: Workshop date

## Organisers
- Peter Knees, Vienna University of Technology, Austria
- Markus Schedl, Johannes Kepler University Linz, Austria
- Rebecca Fiebrink, Goldsmiths, University of London, UK

Contact: [milc2018@easychair.org](mailto:milc2018@easychair.org)

## Program Committee
- Baptiste Caramiaux, IRCAM, France
- Mark Cartwright, New York University, USA
- Matthew Davies, INESC TEC Porto, Portugal
- Christian Dittmar, International Audio Laboratories Erlangen, Germany
- Bruce Ferwerda, Jönköping University, Sweden
- Ichiro Fujinaga, McGill University, Canada
- Jason Hockman, Birmingham City University, UK
- Masataka Goto, National Institute of Advanced Industrial Science and Technology, Japan
- Florian Grote, Native Instruments GmbH, Germany
- Bogdan Ionescu, University Politehnica of Bucharest, Romania
- Vikas Kumar, University of Minnesota, USA
- Cynthia Liem, Delft University of Technology, Netherlands
- Matija Marolt, University of Ljubljana, Slovenia
- Cárthach Ó Nuanáin, Universitat Pompeu Fabra, Spain
- Tae Hong Park, New York University, USA
- Sebastian Stober, University of Potsdam, Germany
- Michael Zbyszynski, Goldsmiths University of London, UK

## Call for Papers
The call for papers can be found online on [EasyChair CFP](https://easychair.org/cfp/milc2018).
